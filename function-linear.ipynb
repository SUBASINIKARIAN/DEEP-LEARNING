{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 6.583440780639648\n",
      "Epoch: 1 Loss: 1.327976942062378\n",
      "Epoch: 2 Loss: 0.034718453884124756\n",
      "Epoch: 3 Loss: 0.024475345388054848\n",
      "Epoch: 4 Loss: 0.018198035657405853\n",
      "Epoch: 5 Loss: 0.6040483117103577\n",
      "Epoch: 6 Loss: 0.3151511549949646\n",
      "Epoch: 7 Loss: 0.214212104678154\n",
      "Epoch: 8 Loss: 0.9674757719039917\n",
      "Epoch: 9 Loss: 0.0536203607916832\n",
      "Epoch: 10 Loss: 0.10637876391410828\n",
      "Epoch: 11 Loss: 0.12109971791505814\n",
      "Epoch: 12 Loss: 0.38357073068618774\n",
      "Epoch: 13 Loss: 0.08627074211835861\n",
      "Epoch: 14 Loss: 0.14827217161655426\n",
      "Epoch: 15 Loss: 0.010342758148908615\n",
      "Epoch: 16 Loss: 0.005843780934810638\n",
      "Epoch: 17 Loss: 0.003187882248312235\n",
      "Epoch: 18 Loss: 0.14154525101184845\n",
      "Epoch: 19 Loss: 0.20647551119327545\n",
      "Epoch: 20 Loss: 0.10253717750310898\n",
      "Epoch: 21 Loss: 0.022600706666707993\n",
      "Epoch: 22 Loss: 0.4539942145347595\n",
      "Epoch: 23 Loss: 0.058836814016103745\n",
      "Epoch: 24 Loss: 0.1207452043890953\n",
      "Epoch: 25 Loss: 0.025232626125216484\n",
      "Epoch: 26 Loss: 0.01595056988298893\n",
      "Epoch: 27 Loss: 0.06340903043746948\n",
      "Epoch: 28 Loss: 0.03956129774451256\n",
      "Epoch: 29 Loss: 1.3369168300414458e-05\n",
      "Epoch: 30 Loss: 0.015109101310372353\n",
      "Epoch: 31 Loss: 0.003956538159400225\n",
      "Epoch: 32 Loss: 0.08457523584365845\n",
      "Epoch: 33 Loss: 0.06284463405609131\n",
      "Epoch: 34 Loss: 0.06770926713943481\n",
      "Epoch: 35 Loss: 0.013326918706297874\n",
      "Epoch: 36 Loss: 0.006292411591857672\n",
      "Epoch: 37 Loss: 0.10298902541399002\n",
      "Epoch: 38 Loss: 2.9487306164810434e-05\n",
      "Epoch: 39 Loss: 0.06254053860902786\n",
      "Epoch: 40 Loss: 0.023759137839078903\n",
      "Epoch: 41 Loss: 0.1568310409784317\n",
      "Epoch: 42 Loss: 0.009241415187716484\n",
      "Epoch: 43 Loss: 0.05329006165266037\n",
      "Epoch: 44 Loss: 0.07881884276866913\n",
      "Epoch: 45 Loss: 0.02829926647245884\n",
      "Epoch: 46 Loss: 0.0019423544872552156\n",
      "Epoch: 47 Loss: 7.617429946549237e-05\n",
      "Epoch: 48 Loss: 0.21478718519210815\n",
      "Epoch: 49 Loss: 0.06640730798244476\n",
      "Epoch: 50 Loss: 0.06854912638664246\n",
      "Epoch: 51 Loss: 8.460574463242665e-08\n",
      "Epoch: 52 Loss: 0.10108356922864914\n",
      "Epoch: 53 Loss: 0.022535232827067375\n",
      "Epoch: 54 Loss: 0.04706582799553871\n",
      "Epoch: 55 Loss: 0.039239488542079926\n",
      "Epoch: 56 Loss: 0.0007677626563236117\n",
      "Epoch: 57 Loss: 0.0017905194545164704\n",
      "Epoch: 58 Loss: 0.1824662983417511\n",
      "Epoch: 59 Loss: 0.026192018762230873\n",
      "Epoch: 60 Loss: 0.46540653705596924\n",
      "Epoch: 61 Loss: 0.17024075984954834\n",
      "Epoch: 62 Loss: 0.04700253903865814\n",
      "Epoch: 63 Loss: 0.18057408928871155\n",
      "Epoch: 64 Loss: 0.008969146758317947\n",
      "Epoch: 65 Loss: 0.03973999619483948\n",
      "Epoch: 66 Loss: 0.03156459704041481\n",
      "Epoch: 67 Loss: 0.027976762503385544\n",
      "Epoch: 68 Loss: 0.013720172457396984\n",
      "Epoch: 69 Loss: 0.11566106975078583\n",
      "Prediction: 2.3836755752563477\n",
      "Expected: [2.513835008]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, MSELoss, functional as F\n",
    "from torch.optim import SGD, Adam, RMSprop\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "def data_generator(data_size=50):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for ix in range(data_size):        \n",
    "        x = np.random.randint(1000) / 1000\n",
    "        y = 7*(x*x*x) + 8*x+ 2\n",
    "        inputs.append([x])\n",
    "        labels.append([y])\n",
    "        \n",
    "    return inputs, labels\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = Linear(1, 6)\n",
    "        self.fc3 = Linear(6, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x   \n",
    "model = Net()\n",
    "\n",
    "critereon = MSELoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 70\n",
    "data_size = 50\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    X, y = data_generator(data_size)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for ix in range(data_size):\n",
    "        y_pred = model(Variable(Tensor(X[ix])))\n",
    "        loss = critereon(y_pred, Variable(Tensor(y[ix]), requires_grad=False)) \n",
    "        # print(loss.data)    \n",
    "        epoch_loss = loss.data\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch, epoch_loss))\n",
    "#test the model\n",
    "\n",
    "model.eval()\n",
    "test_data = data_generator(1)\n",
    "prediction = model(Variable(Tensor(test_data[0][0])))\n",
    "print(\"Predicted_value: {}\".format(prediction.data[0]))\n",
    "print(\"Expected_value: {}\".format(test_data[1][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20283fe50569640ce6993bbef4448865d80db8d227d78093b0242749fcc5e74d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
